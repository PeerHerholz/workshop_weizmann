{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example 1: Preprocessing Workflow\n",
    "\n",
    "This is meant as a very simple example for a preprocessing workflow. In this workflow we will conduct the following steps:\n",
    "\n",
    "1. Motion correction of functional images with FSL's MCFLIRT\n",
    "2. Coregistration of functional images to anatomical images (according to FSL's FEAT pipeline)\n",
    "3. Smoothing of coregistered functional images with FWHM set to 4mm and 8mm\n",
    "4. Artifact Detection in functional images (to detect outlier volumes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation\n",
    "\n",
    "Before we can start with anything we first need to download the data (the other 9 subjects in the dataset). This can be done very quickly with the following `datalad` command.\n",
    "\n",
    "**Note:** This might take a while, as datalad needs to download ~700MB of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "datalad get -J 4 -d /data/ds000114 \\\n",
    "    /data/ds000114/derivatives/fmriprep/sub-*/anat/*preproc.nii.gz \\\n",
    "    /data/ds000114/sub-*/ses-test/func/*fingerfootlips*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect the data\n",
    "\n",
    "For every subject we have one anatomical T1w and 5 functional images. As a short recap, the image properties of the anatomy and the **fingerfootlips** functional image are:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cd /data/ds000114/\n",
    "nib-ls derivatives/fmriprep/sub-01/*/*t1w_preproc.nii.gz sub-01/ses-test/f*/*fingerfootlips*.nii.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**So, let's start!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "First, let's import all the modules we later will be needing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import plotting\n",
    "%matplotlib inline\n",
    "from os.path import join as opj\n",
    "import os\n",
    "import json\n",
    "from nipype.interfaces.fsl import (BET, ExtractROI, FAST, FLIRT, ImageMaths,\n",
    "                                   MCFLIRT, SliceTimer, Threshold)\n",
    "from nipype.interfaces.spm import Smooth\n",
    "from nipype.interfaces.utility import IdentityInterface\n",
    "from nipype.interfaces.io import SelectFiles, DataSink\n",
    "from nipype.algorithms.rapidart import ArtifactDetect\n",
    "from nipype import Workflow, Node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment parameters\n",
    "\n",
    "It's always a good idea to specify all parameters that might change between experiments at the beginning of your script. We will use one functional image for fingerfootlips task for ten subjects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_dir = '/output'\n",
    "output_dir = 'datasink'\n",
    "working_dir = 'workingdir'\n",
    "\n",
    "# list of subject identifiers\n",
    "subject_list = ['01', '02', '03', '04', '05', '06', '07', '08', '09', '10']\n",
    "\n",
    "# list of session identifiers\n",
    "task_list = ['fingerfootlips']\n",
    "\n",
    "# Smoothing widths to apply\n",
    "fwhm = [4, 8]\n",
    "\n",
    "# TR of functional images\n",
    "with open('/data/ds000114/task-fingerfootlips_bold.json', 'rt') as fp:\n",
    "    task_info = json.load(fp)\n",
    "TR = task_info['RepetitionTime']\n",
    "\n",
    "# Isometric resample of functional images to voxel size (in mm)\n",
    "iso_size = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Nodes for the main workflow\n",
    "\n",
    "Initiate all the different interfaces (represented as nodes) that you want to use in your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ExtractROI - skip dummy scans\n",
    "extract = Node(ExtractROI(t_min=4, t_size=-1, output_type='NIFTI'),\n",
    "               name=\"extract\")\n",
    "\n",
    "# MCFLIRT - motion correction\n",
    "mcflirt = Node(MCFLIRT(mean_vol=True,\n",
    "                       save_plots=True,\n",
    "                       output_type='NIFTI'),\n",
    "               name=\"mcflirt\")\n",
    "\n",
    "# SliceTimer - correct for slice wise acquisition\n",
    "slicetimer = Node(SliceTimer(index_dir=False,\n",
    "                             interleaved=True,\n",
    "                             output_type='NIFTI',\n",
    "                             time_repetition=TR),\n",
    "                  name=\"slicetimer\")\n",
    "\n",
    "# Smooth - image smoothing\n",
    "smooth = Node(Smooth(), name=\"smooth\")\n",
    "smooth.iterables = (\"fwhm\", fwhm)\n",
    "\n",
    "# Artifact Detection - determines outliers in functional images\n",
    "art = Node(ArtifactDetect(norm_threshold=2,\n",
    "                          zintensity_threshold=3,\n",
    "                          mask_type='spm_global',\n",
    "                          parameter_source='FSL',\n",
    "                          use_differences=[True, False],\n",
    "                          plot_type='svg'),\n",
    "           name=\"art\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coregistration Workflow\n",
    "\n",
    "Initiate a workflow that coregistrates the functional images to the anatomical image (according to FSL's FEAT pipeline)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BET - Skullstrip anatomical Image\n",
    "bet_anat = Node(BET(frac=0.5,\n",
    "                    robust=True,\n",
    "                    output_type='NIFTI_GZ'),\n",
    "                name=\"bet_anat\")\n",
    "\n",
    "# FAST - Image Segmentation\n",
    "segmentation = Node(FAST(output_type='NIFTI_GZ'),\n",
    "                    name=\"segmentation\", mem_gb=4)\n",
    "\n",
    "# Select WM segmentation file from segmentation output\n",
    "def get_wm(files):\n",
    "    return files[-1]\n",
    "\n",
    "# Threshold - Threshold WM probability image\n",
    "threshold = Node(Threshold(thresh=0.5,\n",
    "                           args='-bin',\n",
    "                           output_type='NIFTI_GZ'),\n",
    "                name=\"threshold\")\n",
    "\n",
    "# FLIRT - pre-alignment of functional images to anatomical images\n",
    "coreg_pre = Node(FLIRT(dof=6, output_type='NIFTI_GZ'),\n",
    "                 name=\"coreg_pre\")\n",
    "\n",
    "# FLIRT - coregistration of functional images to anatomical images with BBR\n",
    "coreg_bbr = Node(FLIRT(dof=6,\n",
    "                       cost='bbr',\n",
    "                       schedule=opj(os.getenv('FSLDIR'),\n",
    "                                    'etc/flirtsch/bbr.sch'),\n",
    "                       output_type='NIFTI_GZ'),\n",
    "                 name=\"coreg_bbr\")\n",
    "\n",
    "# Apply coregistration warp to functional images\n",
    "applywarp = Node(FLIRT(interp='spline',\n",
    "                       apply_isoxfm=iso_size,\n",
    "                       output_type='NIFTI'),\n",
    "                 name=\"applywarp\")\n",
    "\n",
    "# Apply coregistration warp to mean file\n",
    "applywarp_mean = Node(FLIRT(interp='spline',\n",
    "                            apply_isoxfm=iso_size,\n",
    "                            output_type='NIFTI_GZ'),\n",
    "                 name=\"applywarp_mean\")\n",
    "\n",
    "# Create a coregistration workflow\n",
    "coregwf = Workflow(name='coregwf')\n",
    "coregwf.base_dir = opj(experiment_dir, working_dir)\n",
    "\n",
    "# Connect all components of the coregistration workflow\n",
    "coregwf.connect([(bet_anat, segmentation, [('out_file', 'in_files')]),\n",
    "                 (segmentation, threshold, [(('partial_volume_files', get_wm),\n",
    "                                             'in_file')]),\n",
    "                 (bet_anat, coreg_pre, [('out_file', 'reference')]),\n",
    "                 (threshold, coreg_bbr, [('out_file', 'wm_seg')]),\n",
    "                 (coreg_pre, coreg_bbr, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                 (coreg_bbr, applywarp, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                 (bet_anat, applywarp, [('out_file', 'reference')]),\n",
    "                 (coreg_bbr, applywarp_mean, [('out_matrix_file', 'in_matrix_file')]),\n",
    "                 (bet_anat, applywarp_mean, [('out_file', 'reference')]),\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify input & output stream\n",
    "\n",
    "Specify where the input data can be found & where and how to save the output data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Infosource - a function free node to iterate over the list of subject names\n",
    "infosource = Node(IdentityInterface(fields=['subject_id', 'task_name']),\n",
    "                  name=\"infosource\")\n",
    "infosource.iterables = [('subject_id', subject_list),\n",
    "                        ('task_name', task_list)]\n",
    "\n",
    "# SelectFiles - to grab the data (alternativ to DataGrabber)\n",
    "anat_file = opj('derivatives', 'fmriprep', 'sub-{subject_id}', 'anat', 'sub-{subject_id}_t1w_preproc.nii.gz')\n",
    "func_file = opj('sub-{subject_id}', 'ses-test', 'func',\n",
    "                'sub-{subject_id}_ses-test_task-{task_name}_bold.nii.gz')\n",
    "\n",
    "templates = {'anat': anat_file,\n",
    "             'func': func_file}\n",
    "selectfiles = Node(SelectFiles(templates,\n",
    "                               base_directory='/data/ds000114'),\n",
    "                   name=\"selectfiles\")\n",
    "\n",
    "# Datasink - creates output folder for important outputs\n",
    "datasink = Node(DataSink(base_directory=experiment_dir,\n",
    "                         container=output_dir),\n",
    "                name=\"datasink\")\n",
    "\n",
    "## Use the following DataSink output substitutions\n",
    "substitutions = [('_subject_id_', 'sub-'),\n",
    "                 ('_task_name_', '/task-'),\n",
    "                 ('_fwhm_', 'fwhm-'),\n",
    "                 ('_roi', ''),\n",
    "                 ('_mcf', ''),\n",
    "                 ('_st', ''),\n",
    "                 ('_flirt', ''),\n",
    "                 ('.nii_mean_reg', '_mean'),\n",
    "                 ('.nii.par', '.par'),\n",
    "                 ]\n",
    "subjFolders = [('fwhm-%s/' % f, 'fwhm-%s_' % f) for f in fwhm]\n",
    "substitutions.extend(subjFolders)\n",
    "datasink.inputs.substitutions = substitutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specify Workflow\n",
    "\n",
    "Create a workflow and connect the interface nodes and the I/O stream to each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a preprocessing workflow\n",
    "preproc = Workflow(name='preproc')\n",
    "preproc.base_dir = opj(experiment_dir, working_dir)\n",
    "\n",
    "# Connect all components of the preprocessing workflow\n",
    "preproc.connect([(infosource, selectfiles, [('subject_id', 'subject_id'),\n",
    "                                            ('task_name', 'task_name')]),\n",
    "                 (selectfiles, extract, [('func', 'in_file')]),\n",
    "                 (extract, mcflirt, [('roi_file', 'in_file')]),\n",
    "                 (mcflirt, slicetimer, [('out_file', 'in_file')]),\n",
    "\n",
    "                 (selectfiles, coregwf, [('anat', 'bet_anat.in_file'),\n",
    "                                         ('anat', 'coreg_bbr.reference')]),\n",
    "                 (mcflirt, coregwf, [('mean_img', 'coreg_pre.in_file'),\n",
    "                                     ('mean_img', 'coreg_bbr.in_file'),\n",
    "                                     ('mean_img', 'applywarp_mean.in_file')]),\n",
    "                 (slicetimer, coregwf, [('slice_time_corrected_file', 'applywarp.in_file')]),\n",
    "                 \n",
    "                 (coregwf, smooth, [('applywarp.out_file', 'in_files')]),\n",
    "\n",
    "                 (mcflirt, datasink, [('par_file', 'preproc.@par')]),\n",
    "                 (smooth, datasink, [('smoothed_files', 'preproc.@smooth')]),\n",
    "                 (coregwf, datasink, [('applywarp_mean.out_file', 'preproc.@mean')]),\n",
    "\n",
    "                 (coregwf, art, [('applywarp.out_file', 'realigned_files')]),\n",
    "                 (mcflirt, art, [('par_file', 'realignment_parameters')]),\n",
    "\n",
    "                 (coregwf, datasink, [('coreg_bbr.out_matrix_file', 'preproc.@mat_file'),\n",
    "                                      ('bet_anat.out_file', 'preproc.@brain')]),\n",
    "                 (art, datasink, [('outlier_files', 'preproc.@outlier_files'),\n",
    "                                  ('plot_files', 'preproc.@plot_files')]),\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the workflow\n",
    "\n",
    "It always helps to visualize your workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create preproc output graph\n",
    "preproc.write_graph(graph2use='colored', format='png', simple_form=True)\n",
    "\n",
    "# Visualize the graph\n",
    "from IPython.display import Image\n",
    "Image(filename=opj(preproc.base_dir, 'preproc', 'graph.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the detailed graph\n",
    "preproc.write_graph(graph2use='flat', format='png', simple_form=True)\n",
    "Image(filename=opj(preproc.base_dir, 'preproc', 'graph_detailed.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Run the Workflow\n",
    "\n",
    "Now that everything is ready, we can run the preprocessing workflow. Change ``n_procs`` to the number of jobs/cores you want to use. **Note** that if  you're using a Docker container and FLIRT fails to run without any good reason, you might need to change memory settings in the Docker preferences (6 GB should be enough for this workflow)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc.run('MultiProc', plugin_args={'n_procs': 4})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect output\n",
    "\n",
    "Let's check the structure of the output folder, to see if we have everything we wanted to save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tree /output/datasink/preproc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize results\n",
    "\n",
    "Let's check the effect of the different smoothing kernels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nilearn import image, plotting\n",
    "out_path = '/output/datasink/preproc/sub-01/task-fingerfootlips'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_epi(\n",
    "    '/data/ds000114/derivatives/fmriprep/sub-01/anat/sub-01_t1w_preproc.nii.gz',\n",
    "    title=\"T1\", display_mode='ortho', annotate=False, draw_cross=False, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_epi(opj(out_path, 'sub-01_ses-test_task-fingerfootlips_bold_mean.nii.gz'),\n",
    "                  title=\"fwhm = 0mm\", display_mode='ortho', annotate=False, draw_cross=False, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_epi(image.mean_img(opj(out_path, 'fwhm-4_ssub-01_ses-test_task-fingerfootlips_bold.nii')),\n",
    "                  title=\"fwhm = 4mm\", display_mode='ortho', annotate=False, draw_cross=False, cmap='gray');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotting.plot_epi(image.mean_img(opj(out_path, 'fwhm-8_ssub-01_ses-test_task-fingerfootlips_bold.nii')),\n",
    "                  title=\"fwhm = 8mm\", display_mode='ortho', annotate=False, draw_cross=False, cmap='gray');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's investigate the motion parameters. How much did the subject move and turn in the scanner?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "par = np.loadtxt('/output/datasink/preproc/sub-01/task-fingerfootlips/sub-01_ses-test_task-fingerfootlips_bold.par')\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 5))\n",
    "axes[0].set_ylabel('rotation (radians)')\n",
    "axes[0].plot(par[0:, :3])\n",
    "axes[1].plot(par[0:, 3:])\n",
    "axes[1].set_xlabel('time (TR)')\n",
    "axes[1].set_ylabel('translation (mm)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There seems to be a rather drastic motion around volume 102. Let's check if the outliers detection algorithm was able to pick this up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "outlier_ids = np.loadtxt('/output/datasink/preproc/sub-01/task-fingerfootlips/art.sub-01_ses-test_task-fingerfootlips_bold_outliers.txt')\n",
    "print('Outliers were detected at volumes: %s' % outlier_ids)\n",
    "\n",
    "from IPython.display import SVG\n",
    "SVG(filename='/output/datasink/preproc/sub-01/task-fingerfootlips/plot.sub-01_ses-test_task-fingerfootlips_bold.svg')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
