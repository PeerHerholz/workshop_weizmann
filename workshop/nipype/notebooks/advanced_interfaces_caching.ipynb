{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interface caching\n",
    "\n",
    "This section details the interface-caching mechanism, exposed in the `nipype.caching` module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interface caching: why and how\n",
    "\n",
    "* `Pipelines` (also called `workflows`) specify processing by an execution graph. This is useful because it opens the door to dependency checking and enables\n",
    "    - to minimize recomputations, \n",
    "    - to have the execution engine transparently deal with intermediate file manipulations.\n",
    "\n",
    "  They, however, do not blend in well with arbitrary Python code, as they must rely on their own execution engine.\n",
    "\n",
    "\n",
    "* `Interfaces` give fine control of the execution of each step with a thin wrapper on the underlying software. As a result that can easily be inserted in Python code.  \n",
    "\n",
    "  However, they force the user to specify explicit input and output file names and cannot do any caching.\n",
    "\n",
    "This is why nipype exposes an intermediate mechanism, `caching` that provides transparent output file management and caching within imperative Python code rather than a workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A big picture view: using the [`Memory`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#memory) object\n",
    "\n",
    "nipype caching relies on the [`Memory`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#memory) class: it creates an\n",
    "execution context that is bound to a disk cache:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.caching import Memory\n",
    "mem = Memory(base_dir='.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the caching directory is a subdirectory called `nipype_mem` of the given `base_dir`. This is done to avoid polluting the base director.\n",
    "\n",
    "In the corresponding execution context, nipype interfaces can be turned into callables that can be used as functions using the [`Memory.cache`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#nipype.caching.memory.Memory.cache) method. For instance, if we want to run the fslMerge command on a set of files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype.interfaces import fsl\n",
    "fsl_merge = mem.cache(fsl.Merge)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the [`Memory.cache`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#nipype.caching.memory.Memory.cache) method takes interfaces **classes**, and not instances.\n",
    "\n",
    "The resulting `fsl_merge` object can be applied as a function to parameters, that will form the inputs of the `merge` fsl commands. Those inputs are given as keyword arguments, bearing the same name as the name in the inputs specs of the interface. In IPython, you can also get the argument list by using the `fsl_merge?` syntax to inspect the docs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "In [3]: fsl_merge?\n",
    "String Form:PipeFunc(nipype.interfaces.fsl.utils.Merge,\n",
    "                     base_dir=/home/varoquau/dev/nipype/nipype/caching/nipype_mem)\n",
    "Namespace:  Interactive\n",
    "File:       /home/varoquau/dev/nipype/nipype/caching/memory.py\n",
    "Definition: fsl_merge(self, **kwargs)\n",
    "Docstring:  Use fslmerge to concatenate images\n",
    "\n",
    "Inputs\n",
    "------\n",
    "\n",
    "Mandatory:\n",
    "dimension: dimension along which the file will be merged\n",
    "in_files:  None\n",
    "\n",
    "Optional:\n",
    "args: Additional parameters to the command\n",
    "environ: Environment variables (default={})\n",
    "ignore_exception: Print an error message instead of throwing an exception in case the interface fails to run (default=False)\n",
    "merged_file: None\n",
    "output_type: FSL output type\n",
    "\n",
    "Outputs\n",
    "-------\n",
    "merged_file: None\n",
    "Class Docstring:\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus `fsl_merge` is applied to parameters as such:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = '/data/ds000114/sub-01/ses-test/func/sub-01_ses-test_task-fingerfootlips_bold.nii.gz'\n",
    "\n",
    "results = fsl_merge(dimension='t', in_files=[filepath, filepath])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are standard nipype nodes results. In particular, they expose an `outputs` attribute that carries all the outputs of the process, as specified by the docs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.outputs.merged_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, and most important, if the node is applied to the same input parameters, it is not computed, and the results are reloaded from the disk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = fsl_merge(dimension='t', in_files=[filepath, filepath])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the [`Memory`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#memory) is set up and you are applying it to data, an important thing to keep in mind is that you are using up disk cache. It might be useful to clean it using the methods that [`Memory`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#memory) provides for this: [`Memory.clear_previous_runs`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#nipype.caching.memory.Memory.clear_previous_runs), [`Memory.clear_runs_since`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#nipype.caching.memory.Memory.clear_runs_since)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "\n",
    "A full-blown example showing how to stage multiple operations can be found in the [`caching_example.py`](http://nipype.readthedocs.io/en/latest/_downloads/howto_caching_example.py) file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage patterns: working efficiently with caching\n",
    "\n",
    "The goal of the `caching` module is to enable writing plain Python code rather than workflows. Use it: instead of data grabber nodes, use for instance the `glob` module. To vary parameters, use `for` loops. To make reusable code, write Python functions.\n",
    "\n",
    "One good rule of thumb to respect is to avoid the usage of explicit filenames apart from the outermost inputs and outputs of your processing. The reason being that the caching mechanism of `nipy.caching` takes care of generating the unique hashes, ensuring that, when you vary parameters, files are not overridden by the output of different computations.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "**Debugging**:  \n",
    "If you need to inspect the running environment of the nodes, it may be useful to know where they were executed. With `nipype.caching`, you do not control this location as it is encoded by hashes.  \n",
    "To find out where an operation has been persisted, simply look in it's output variable:  \n",
    "```out.runtime.cwd```\n",
    "</div>\n",
    "\n",
    "Finally, the more you explore different parameters, the more you risk creating cached results that will never be reused. Keep in mind that it may be useful to flush the cache using [`Memory.clear_previous_runs`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#nipype.caching.memory.Memory.clear_previous_runs) or [`Memory.clear_runs_since`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html#nipype.caching.memory.Memory.clear_runs_since)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API reference\n",
    "\n",
    "For more info about the API, go to [`caching.memory`](http://nipype.readthedocs.io/en/latest/api/generated/nipype.caching.memory.html)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
