{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Configuration Options\n",
    "\n",
    "Nipype gives you many liberties on how to create workflows, but the execution of them uses a lot of default parameters. But you have of course all the freedom to change them as you like.\n",
    "\n",
    "Nipype looks for the configuration options in the local folder under the name ``nipype.cfg`` and in ``~/.nipype/nipype.cfg`` (in this order). It can be divided into **Logging** and **Execution** options. A few of the possible options are the following:\n",
    "\n",
    "### Logging\n",
    "\n",
    "- **`workflow_level`**: How detailed the logs regarding workflow should be  \n",
    "    (possible values: ``INFO`` and ``DEBUG``; default value: ``INFO``)\n",
    "\n",
    "\n",
    "- **`utils_level`**: How detailed the logs regarding nipype utils, like file operations (for example overwriting warning) or the resource profiler, should be  \n",
    "    (possible values: ``INFO`` and ``DEBUG``; default value: ``INFO``)\n",
    "\n",
    "\n",
    "- **`interface_level`**: How detailed the logs regarding interface execution should be  \n",
    "    (possible values: ``INFO`` and ``DEBUG``; default value: ``INFO``)\n",
    "\n",
    "\n",
    "- **`filemanip_level`** (deprecated as of 1.0): How detailed the logs regarding file operations (for example overwriting warning) should be  \n",
    "    (possible values: ``INFO`` and ``DEBUG``)\n",
    "\n",
    "\n",
    "- **`log_to_file`**: Indicates whether logging should also send the output to a file  \n",
    "    (possible values: ``true`` and ``false``; default value: ``false``)\n",
    "\n",
    "\n",
    "- **`log_directory`**: Where to store logs.  \n",
    "    (string, default value: home directory)\n",
    "\n",
    "\n",
    "- **`log_size`**: Size of a single log file.  \n",
    "    (integer, default value: 254000)\n",
    "\n",
    "\n",
    "- **`log_rotate`**: How many rotations should the log file make.  \n",
    "    (integer, default value: 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "- **`plugin`**: This defines which execution plugin to use.  \n",
    "    (possible values: ``Linear``, ``MultiProc``, ``SGE``, ``IPython``; default value: ``Linear``)\n",
    "\n",
    "\n",
    "- **`stop_on_first_crash`**: Should the workflow stop upon the first node crashing or try to execute as many\n",
    "    nodes as possible?  \n",
    "    (possible values: ``true`` and ``false``; default value: ``false``)\n",
    "\n",
    "\n",
    "- **`stop_on_first_rerun`**: Should the workflow stop upon the first node trying to recompute (by that we mean rerunning a node that has been run before - this can happen due changed inputs and/or hash_method since the last run).  \n",
    "    (possible values: ``true`` and ``false``; default value: ``false``)\n",
    "\n",
    "\n",
    "- **`hash_method`**: Should the input files be checked for changes using their content (slow, but 100% accurate) or just their size and modification date (fast, but potentially prone to errors)?  \n",
    "    (possible values: ``content`` and ``timestamp``; default value: ``timestamp``)\n",
    "\n",
    "\n",
    "- **`keep_inputs`**: Ensures that all inputs that are created in the nodes working directory are\n",
    "    kept after node execution  \n",
    "    (possible values: ``true`` and ``false``; default value: ``false``)\n",
    "\n",
    "\n",
    "- **`single_thread_matlab`**: Should all of the Matlab interfaces (including SPM) use only one thread? This is useful if you are parallelizing your workflow using MultiProc or IPython on a single multicore machine.  \n",
    "    (possible values: ``true`` and ``false``; default value: ``true``)\n",
    "\n",
    "\n",
    "- **`display_variable`**: Override the ``$DISPLAY`` environment variable for interfaces that require an X server. This option is useful if there is a running X server, but ``$DISPLAY`` was not defined in nipype's environment. For example, if an X server is listening on the default port of 6000, set ``display_variable = :0`` to enable nipype interfaces to use it. It may also point to displays provided by VNC, [xnest](http://www.x.org/archive/X11R7.5/doc/man/man1/Xnest.1.html) or [Xvfb](http://www.x.org/archive/X11R6.8.1/doc/Xvfb.1.html).  \n",
    "    If neither ``display_variable`` nor the ``$DISPLAY`` environment variable is     set, nipype will try to configure a new virtual server using Xvfb.  \n",
    "     (possible values: any X server address; default value: not set)\n",
    "\n",
    "\n",
    "- **`remove_unnecessary_outputs`**: This will remove any interface outputs not needed by the workflow. If the\n",
    "    required outputs from a node changes, rerunning the workflow will rerun the\n",
    "    node. Outputs of leaf nodes (nodes whose outputs are not connected to any\n",
    "    other nodes) will never be deleted independent of this parameter.  \n",
    "    (possible values: ``true`` and ``false``; default value: ``true``)\n",
    "\n",
    "\n",
    "- **`try_hard_link_datasink`**: When the DataSink is used to produce an organized output file outside\n",
    "    of nipypes internal cache structure, a file system hard link will be\n",
    "    attempted first. A hard link allows multiple file paths to point to the\n",
    "    same physical storage location on disk if the conditions allow. By\n",
    "    referring to the same physical file on disk (instead of copying files\n",
    "    byte-by-byte) we can avoid unnecessary data duplication.  If hard links\n",
    "    are not supported for the source or destination paths specified, then\n",
    "    a standard byte-by-byte copy is used.   \n",
    "    (possible values: ``true`` and ``false``; default value: ``true``)\n",
    "\n",
    "\n",
    "- **`use_relative_paths`**: Should the paths stored in results (and used to look for inputs)\n",
    "    be relative or absolute. Relative paths allow moving the whole\n",
    "    working directory around but may cause problems with\n",
    "    symlinks.  \n",
    "    (possible values: ``true`` and ``false``; default value: ``false``)\n",
    "\n",
    "\n",
    "- **`local_hash_check`**: Perform the hash check on the job submission machine. This option minimizes\n",
    "    the number of jobs submitted to a cluster engine or a multiprocessing pool\n",
    "    to only those that need to be rerun.  \n",
    "    (possible values: ``true`` and ``false``; default value: ``true``)\n",
    "\n",
    "\n",
    "- **`job_finished_timeout`**: When batch jobs are submitted through, SGE/PBS/Condor they could be killed\n",
    "    externally. Nipype checks to see if a results file exists to determine if\n",
    "    the node has completed. This timeout determines for how long this check is\n",
    "    done after a job finish is detected. (float in seconds; default value: 5)\n",
    "\n",
    "\n",
    "- **`remove_node_directories`** (EXPERIMENTAL): Removes directories whose outputs have already been used\n",
    "    up. Doesn't work with IdentiInterface or any node that patches\n",
    "    data through (without copying)  \n",
    "    (possible values: ``true`` and ``false``; default value: ``false``)\n",
    "\n",
    "\n",
    "- **`stop_on_unknown_version`**: If this is set to True, an underlying interface will raise an error, when no\n",
    "    version information is available. Please notify developers or submit a patch.\n",
    "\n",
    "\n",
    "- **`parameterize_dirs`**: If this is set to True, the node's output directory will contain full\n",
    "    parameterization of any iterable, otherwise parameterizations over 32\n",
    "    characters will be replaced by their hash.  \n",
    "    (possible values: ``true`` and ``false``; default value: ``true``)\n",
    "\n",
    "\n",
    "- **`poll_sleep_duration`**: This controls how long the job submission loop will sleep between submitting\n",
    "    all pending jobs and checking for job completion. To be nice to cluster\n",
    "    schedulers the default is set to 2 seconds.\n",
    "\n",
    "\n",
    "- **`xvfb_max_wait`**: Maximum time (in seconds) to wait for Xvfb to start, if the _redirect_x\n",
    "    parameter of an Interface is True.\n",
    "\n",
    "\n",
    "- **`crashfile_format`**: This option controls the file type of any crashfile generated. Pklz\n",
    "    crashfiles allow interactive debugging and rerunning of nodes, while text\n",
    "    crashfiles allow portability across machines and shorter load time.  \n",
    "    (possible values: ``pklz`` and ``txt``; default value: ``pklz``)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resource Monitor\n",
    "\n",
    "- **`enabled`**: Enables monitoring the resources occupation (possible values: ``true`` and\n",
    "    ``false``; default value: ``false``). All the following options will be\n",
    "    dismissed if the resource monitor is not enabled.\n",
    "\n",
    "\n",
    "- **`sample_frequency`**: Sampling period (in seconds) between measurements of resources (memory, cpus)\n",
    "    being used by an interface  \n",
    "    (default value: ``1``)\n",
    "\n",
    "\n",
    "- **`summary_file`**: Indicates where the summary file collecting all profiling information from the\n",
    "    resource monitor should be stored after execution of a workflow.\n",
    "    The ``summary_file`` does not apply to interfaces run independently.\n",
    "    (unset by default, in which case the summary file will be written out to \n",
    "    ``<base_dir>/resource_monitor.json`` of the top-level workflow).\n",
    "\n",
    "\n",
    "- **`summary_append`**: Append to an existing summary file (only applies to workflows).  \n",
    "    (default value: ``true``, possible values: ``true`` or ``false``)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example\n",
    "\n",
    "    [logging]\n",
    "    workflow_level = DEBUG\n",
    "\n",
    "    [execution]\n",
    "    stop_on_first_crash = true\n",
    "    hash_method = timestamp\n",
    "    display_variable = :1\n",
    "\n",
    "    [monitoring]\n",
    "    enabled = false\n",
    "    \n",
    "`Workflow.config` property has a form of a nested dictionary reflecting the structure of the `.cfg` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import Workflow\n",
    "myworkflow = Workflow(name='myworkflow')\n",
    "myworkflow.config['execution'] = {'stop_on_first_rerun': 'True',\n",
    "                                  'hash_method': 'timestamp'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly set global config options in your workflow script. An\n",
    "example is shown below. This needs to be called before you import the\n",
    "pipeline or the logger. Otherwise, logging level will not be reset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import config\n",
    "cfg = dict(logging=dict(workflow_level = 'DEBUG'),\n",
    "         execution={'stop_on_first_crash': False,\n",
    "                    'hash_method': 'content'})\n",
    "config.update_config(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enabling logging to file\n",
    "\n",
    "By default, logging to file is disabled. One can enable and write the file to\n",
    "a location of choice as in the example below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from nipype import config, logging\n",
    "config.update_config({'logging': {'log_directory': os.getcwd(),\n",
    "                                  'log_to_file': True}})\n",
    "logging.update_logging(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logging update line is necessary to change the behavior of logging such as\n",
    "output directory, logging level, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debug configuration\n",
    "\n",
    "To enable debug mode, one can insert the following lines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import config\n",
    "config.enable_debug_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this mode the following variables are set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "config.set('execution', 'stop_on_first_crash', 'true')\n",
    "config.set('execution', 'remove_unnecessary_outputs', 'false')\n",
    "config.set('execution', 'keep_inputs', 'true')\n",
    "config.set('logging', 'workflow_level', 'DEBUG')\n",
    "config.set('logging', 'interface_level', 'DEBUG')\n",
    "config.set('logging', 'utils_level', 'DEBUG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The primary loggers (`workflow`, `interface` and `utils`) are also reset to level `DEBUG`.\n",
    "\n",
    "You may wish to adjust these manually using:\n",
    "```python\n",
    "from nipype import logging\n",
    "logging.getLogger(<logger>).setLevel(<level>)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Global, workflow & node level\n",
    "\n",
    "The configuration options can be changed globally (i.e. for all workflows), for just a workflow, or for just a node. The implementations look as follows (note that you should first create directories if you want to change `crashdump_dir` and `log_directory`):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the global level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import config, logging\n",
    "import os\n",
    "os.makedirs('/output/log_folder', exist_ok=True)\n",
    "os.makedirs('/output/crash_folder', exist_ok=True)\n",
    "\n",
    "config_dict={'execution': {'remove_unnecessary_outputs': 'true',\n",
    "                           'keep_inputs': 'false',\n",
    "                           'poll_sleep_duration': '60',\n",
    "                           'stop_on_first_rerun': 'false',\n",
    "                           'hash_method': 'timestamp',\n",
    "                           'local_hash_check': 'true',\n",
    "                           'create_report': 'true',\n",
    "                           'crashdump_dir': '/output/crash_folder',\n",
    "                           'use_relative_paths': 'false',\n",
    "                           'job_finished_timeout': '5'},\n",
    "             'logging': {'workflow_level': 'INFO',\n",
    "                         'filemanip_level': 'INFO',\n",
    "                         'interface_level': 'INFO',\n",
    "                         'log_directory': '/output/log_folder',\n",
    "                         'log_to_file': 'true'}}\n",
    "config.update_config(config_dict)\n",
    "logging.update_logging(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the workflow level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import Workflow\n",
    "wf = Workflow(name=\"config_test\")\n",
    "\n",
    "# Change execution parameters\n",
    "wf.config['execution']['stop_on_first_crash'] = 'true'\n",
    "\n",
    "# Change logging parameters\n",
    "wf.config['logging'] = {'workflow_level' : 'DEBUG',\n",
    "                        'filemanip_level' : 'DEBUG',\n",
    "                        'interface_level' : 'DEBUG',\n",
    "                        'log_to_file' : 'True',\n",
    "                        'log_directory' : '/output/log_folder'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### At the node level:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nipype import Node\n",
    "from nipype.interfaces.fsl import BET\n",
    "\n",
    "bet = Node(BET(), name=\"config_test\")\n",
    "\n",
    "bet.config = {'execution': {'keep_unnecessary_outputs': 'false'}}"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
